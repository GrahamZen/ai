{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T13:59:43.907111Z",
     "start_time": "2020-10-22T13:59:43.388800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T13:59:43.954080Z",
     "start_time": "2020-10-22T13:59:43.942086Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    mask = (x > 0)\n",
    "    positive_out = np.zeros_like(x, dtype='float64')\n",
    "    negative_out = np.zeros_like(x, dtype='float64')\n",
    "    \n",
    "    # 大于0的情况\n",
    "    positive_out = 1 / (1 + np.exp(-x, positive_out, where=mask))\n",
    "    # 清除对小于等于0元素的影响\n",
    "    positive_out[~mask] = 0\n",
    "    \n",
    "    # 小于等于0的情况\n",
    "    expX = np.exp(x,negative_out,where=~mask)\n",
    "    negative_out = expX / (1+expX)\n",
    "    # 清除对大于0元素的影响\n",
    "    negative_out[mask] = 0\n",
    "    \n",
    "    return positive_out + negative_out        \n",
    "def invSigmoid(x):\n",
    "    return [math.log(i/(1-i))for i in x]\n",
    "def sigmoid_prime(sigmoidx):\n",
    "    return np.multiply(sigmoidx,1-sigmoidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T13:59:44.972092Z",
     "start_time": "2020-10-22T13:59:44.923103Z"
    }
   },
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    def __init__(self,sizes):\n",
    "#         输入层之外的层数,例子为1+2，layNum=3\n",
    "        self.num_layers =len(sizes)\n",
    "        self.sizes=sizes\n",
    "#         i索引W(i+1)矩阵\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        \n",
    "    def forward_pass(self,x):\n",
    "        a=np.matrix(x).transpose()\n",
    "        for w,b in zip(self.weights,self.biases):\n",
    "            z=w*a+b\n",
    "            a=sigmoid(z)\n",
    "        return float(z)\n",
    "    \n",
    "    def backPropagation(self,x,y):\n",
    "        grad_w=[np.zeros(w.shape)for w in self.weights]\n",
    "        grad_b=[np.zeros(b.shape)for b in self.biases]\n",
    "        delta=[np.zeros(b.shape)for b in self.biases]\n",
    "        a=np.matrix(x).transpose()\n",
    "        alist=[a]\n",
    "        zlist=[]\n",
    "        for w,b in zip(self.weights,self.biases):\n",
    "            z=w*a+b\n",
    "            a=sigmoid(z)\n",
    "            zlist.append(z)\n",
    "            alist.append(a)\n",
    "        alist[-1]=zlist[-1]\n",
    "        delta[-1]=(z-y).transpose()\n",
    "        for l in range(2,self.num_layers):\n",
    "            delta[-l]=np.multiply(sigmoid_prime(alist[-l]),self.weights[1-l].transpose()*delta[1-l])\n",
    "        for i in range(self.num_layers-1):\n",
    "            grad_w[i]=delta[i]*np.mat(alist[i]).transpose()\n",
    "        return grad_w, delta\n",
    "    def SGD(self,train_set,validation_set,batch_size,lr=1e-3,epochs=1e3):\n",
    "        variate=float('inf')\n",
    "        besta=None\n",
    "        for j in range(int(epochs)):\n",
    "            np.random.shuffle(train_set)\n",
    "            mini_batches = [train_set[k:k+batch_size] for k in range(0, train_set.shape[0], batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.minibatch(mini_batch, eta)\n",
    "            curVar=self.validate(validation_set)\n",
    "            if curVar<variate:\n",
    "                variate=curVar\n",
    "                besta=copy.deepcopy(self)\n",
    "            print(\"Epoch {} : {}, best : {}\".format(j,curVar,variate));\n",
    "        return besta\n",
    "    def gradient_descent(self,x,y,lr=1e-3):\n",
    "        grad_w,grad_b=self.backPropagation(x,y)\n",
    "        self.weights=[w-lr*gw for w,gw in zip(self.weights,grad_w)]\n",
    "        self.biases=[b-lr*gb for b,gb in zip(self.biases,grad_b)]\n",
    "    def train(self,train_set,lr=1):\n",
    "        for row in train_set:\n",
    "            self.gradient_descent(row[:-1],row[-1],lr)\n",
    "    def minibatch(self,batch,lr=1e-3):\n",
    "        batchsize=len(batch)\n",
    "        grad_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        grad_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for row in batch:\n",
    "            delta_gw,delta_gb=self.backPropagation(row[:-1],row[-1])\n",
    "            grad_w=[gw+dgw for gw,dgw in zip(grad_w,delta_gw)]\n",
    "            grad_b=[gb+dgb for gb,dgb in zip(grad_b,delta_gb)]\n",
    "        self.weights=[w-lr/batchsize*gw for w,gw in zip(self.weights,grad_w)]\n",
    "        self.biases=[b-lr/batchsize*gb for b,gb in zip(self.biases,grad_b)]\n",
    "    def validate(self,validation_set):\n",
    "        arr=[self.forward_pass(row[:-1])for row in validation_set]\n",
    "        return sum(np.square(arr-validation_set[:,-1]))/validation_set.shape[0]\n",
    "def preprocess(dataSet):\n",
    "    dataSet.dteday=dataSet.dteday.map(date2int)\n",
    "    maxdte=float(max(dataSet.dteday))\n",
    "    dataSet.dteday=dataSet.dteday.map(lambda x:float(x)/maxdte)\n",
    "    return dataSet.values[:,1:]\n",
    "def random_choice(train_set,batchSize):\n",
    "    return train_set[np.random.randint(0,train_set.shape[0],10), :]\n",
    "def date2int(str):\n",
    "    l=[int(x) for x in str.split('/')]\n",
    "    return l[0]+l[1]*30+l[2]\n",
    "def calcVar(ds,a):\n",
    "    arr=[]\n",
    "    for i in range(ds.shape[0]):\n",
    "        arr.append(a.forward_pass(ds[i][:-1]))\n",
    "    return np.var((np.matrix(arr)-ds[:,-1]))\n",
    "def split(dataSet,proportion):\n",
    "    np.random.shuffle(dataSet)\n",
    "    train_num=int(dataSet.shape[0]*proportion)\n",
    "    return dataSet[0:train_num,:],dataSet[train_num:,:]\n",
    "def compute_eta_t(eta_min, eta_max, T_cur, Ti):\n",
    "    '''Equation (5).\n",
    "    # Arguments\n",
    "        eta_min,eta_max,T_cur,Ti are same as equation.\n",
    "    # Returns\n",
    "        eta_t\n",
    "    '''\n",
    "    pi = np.pi\n",
    "    eta_t = eta_min + 0.5 * (eta_max - eta_min) * (np.cos(pi * T_cur / Ti) + 1)\n",
    "    return eta_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T14:00:36.219001Z",
     "start_time": "2020-10-22T14:00:36.148668Z"
    }
   },
   "outputs": [],
   "source": [
    "# 初始化\n",
    "dataSet=pd.read_csv('lab4_dataset/train.csv')\n",
    "ds=preprocess(dataSet)\n",
    "ts,vs=split(ds,0.8)\n",
    "inputNode=ds.shape[1]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T14:00:02.045556Z",
     "start_time": "2020-10-22T13:59:51.075391Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 双隐藏层\n",
    "learningRate=0.1\n",
    "maxj=5\n",
    "for j in range(maxj):\n",
    "    a=ANN([inputNode,80,80,1])\n",
    "    eta=learningRate/(10**j)\n",
    "    besta = a.SGD(ts,vs,128,eta,500)\n",
    "    deviate = besta.validate(vs)\n",
    "    print('d:',deviate,'lr = ',eta )\n",
    "#         if((deviate-min_deviate)/min_deviate>0.01 or abs(deviate-min_deviate)<1e-2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T01:37:14.075720Z",
     "start_time": "2020-10-21T00:21:39.052045Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 单隐藏层\n",
    "learningRate=0.1\n",
    "maxj=5\n",
    "for j in range(maxj):\n",
    "    a=ANN([inputNode,80,1])\n",
    "    eta=learningRate/(10**j)\n",
    "    besta = a.SGD(ts,vs,128,eta,500)\n",
    "    deviate = besta.validate(vs)\n",
    "    print('d:',deviate,'lr = ',eta )\n",
    "#         if((deviate-min_deviate)/min_deviate>0.01 or abs(deviate-min_deviate)<1e-2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T18:46:33.425075Z",
     "start_time": "2020-10-20T17:19:25.763770Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 节点个数\n",
    "learningRate=0.0001\n",
    "maxj=5\n",
    "for j in range(maxj):\n",
    "    a=ANN([inputNode,int(256/(2**j)),1])\n",
    "    eta=learningRate\n",
    "    besta = a.SGD(ts,vs,128,eta,500)\n",
    "    deviate = besta.validate(vs)\n",
    "    print('d:',deviate,'lr = ',eta )\n",
    "#         if((deviate-min_deviate)/min_deviate>0.01 or abs(deviate-min_deviate)<1e-2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T20:34:26.818158Z",
     "start_time": "2020-10-20T18:46:33.459077Z"
    }
   },
   "outputs": [],
   "source": [
    "# mini-batch size\n",
    "learningRate=0.001\n",
    "maxj=5\n",
    "for j in range(maxj):\n",
    "    a=ANN([inputNode,256,1])\n",
    "    eta=learningRate\n",
    "    besta = a.SGD(ts,vs,int(1024/(2**j)),eta,500)\n",
    "    deviate = besta.validate(vs)\n",
    "    print('d:',deviate,'lr = ',eta )\n",
    "#         if((deviate-min_deviate)/min_deviate>0.01 or abs(deviate-min_deviate)<1e-2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T06:31:22.714804Z",
     "start_time": "2020-10-21T01:37:14.126657Z"
    }
   },
   "outputs": [],
   "source": [
    "# 单隐藏层\n",
    "learningRate=0.1\n",
    "maxj=5\n",
    "for j in range(maxj):\n",
    "    a=ANN([inputNode,80,80,80,1])\n",
    "    eta=learningRate/(10**j)\n",
    "    besta = a.SGD(ts,vs,128,eta,500)\n",
    "    deviate = besta.validate(vs)\n",
    "    print('d:',deviate,'lr = ',eta )\n",
    "#         if((deviate-min_deviate)/min_deviate>0.01 or abs(deviate-min_deviate)<1e-2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T14:01:39.118190Z",
     "start_time": "2020-10-22T14:01:31.689405Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最好训练\n",
    "learningRate=1e-4\n",
    "a=ANN([inputNode,80,80,1])\n",
    "besta=a\n",
    "maxj=10\n",
    "for j in range(maxj):\n",
    "    a=besta\n",
    "    eta=compute_eta_t(0,learningRate,j,maxj)\n",
    "    besta = a.SGD(ts,vs,128,eta,1000)\n",
    "    deviate = besta.validate(vs)\n",
    "    print('d:',deviate,'lr = ',eta )\n",
    "#         if((deviate-min_deviate)/min_deviate>0.01 or abs(deviate-min_deviate)<1e-2):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda4695e5f7bc8c4dc3ac8217854788797a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "429.4px",
    "left": "1268.4px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
